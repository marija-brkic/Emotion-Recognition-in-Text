{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf111bbd-7163-4f24-a6b5-c169bdb5de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the emotion dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "# Check dataset structure\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28eac533-3db5-4919-80dc-8893100ed29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT-based transformers model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24f743d1-4c77-4414-b96d-e290d232eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'i didnt feel humiliated', 'label': 0, 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Data\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Print a sample\n",
    "print(tokenized_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a76e5845-398f-48dc-aa54-a0c068935772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.5715102157451064, 1.2351397251814111, 2.044989775051125, 4.662004662004662, 1.3766993632765445, 0.49732686808404825]\n"
     ]
    }
   ],
   "source": [
    "# Handle Class Imbalance\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# Count label distribution in training data\n",
    "labels = dataset[\"train\"][\"label\"]\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "# Compute class weights\n",
    "num_samples = len(labels)\n",
    "num_classes = len(label_counts)\n",
    "class_weights = [num_samples / (num_classes * count) for count in label_counts.values()]\n",
    "class_weights_tensor = torch.tensor(class_weights)\n",
    "\n",
    "print(f\"Class Weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45c85b92-8324-4e60-bffe-7b0f08433f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Arguments & Trainer\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # Evaluate after every epoch\n",
    "    save_strategy=\"epoch\",  # Save best model at the end\n",
    "    learning_rate=1e-5,  # Lower learning rate improves generalization\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,  # Train for longer\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55dc9dcc-ef99-45df-8a76-32d66d444d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 5:12:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.228848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.177630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.178826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.176363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.184593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.22754581909179689, metrics={'train_runtime': 18753.6454, 'train_samples_per_second': 4.266, 'train_steps_per_second': 0.267, 'total_flos': 2.104964038656e+16, 'train_loss': 0.22754581909179689, 'epoch': 5.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e2b22c9a-5d5f-4f52-8efb-a6bd1415a90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model on Test Data\n",
    "\n",
    "import evaluate\n",
    "\n",
    "# Load accuracy metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Get model predictions\n",
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = metric.compute(predictions=preds, references=tokenized_datasets[\"test\"][\"label\"])\n",
    "print(f\"Test Accuracy: {accuracy['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7dc39999-1c16-438a-8451-f494d5217b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve Model Generalization (Fix Overfitting)\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]  # Stop if no improvement after 1 epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0186cc87-3917-4dda-937f-f6d1c9ea9878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Apply Dropout Regularization in the model\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6, hidden_dropout_prob=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd4c81c0-94cd-4571-aa1b-6863476c20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.96      0.96      0.96       581\n",
      "         joy       0.95      0.95      0.95       695\n",
      "        love       0.83      0.81      0.82       159\n",
      "       anger       0.93      0.90      0.91       275\n",
      "        fear       0.86      0.88      0.87       224\n",
      "    surprise       0.70      0.77      0.73        66\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.87      0.88      0.87      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze Model Errors (Classification Report)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = tokenized_datasets[\"test\"][\"label\"]\n",
    "print(classification_report(labels, preds, target_names=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32acaeec-2d3c-4db3-9607-44099335c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label  predictions\n",
      "1479  i really feel and i know the devil hates that ...      1            3\n",
      "457   i cant do strappy shoes at work i just feel we...      4            5\n",
      "917   i feel the need to pimp this since raini my be...      1            2\n",
      "1936  im polyamorous something im starting to feel t...      2            1\n",
      "863   i feel betrayed and angry and sad at the same ...      3            0\n",
      "1764  i don t know how else to describe it except to...      1            2\n",
      "820            i found myself feeling a bit overwhelmed      5            4\n",
      "625   i am feeling overwhelmed by trying to do it al...      5            4\n",
      "1087  i feel for all of you who have been supporting...      1            2\n",
      "688                             i feel hated in cempaka      0            3\n"
     ]
    }
   ],
   "source": [
    "# Analyze Misclassifications\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert test data to DataFrame\n",
    "df_test = dataset[\"test\"].to_pandas()\n",
    "df_test[\"predictions\"] = preds\n",
    "\n",
    "# Show misclassified examples\n",
    "misclassified = df_test[df_test[\"label\"] != df_test[\"predictions\"]]\n",
    "print(misclassified.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5545c002-4dee-437d-abba-f70d626968e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./best_emotion_model/tokenizer_config.json',\n",
       " './best_emotion_model/special_tokens_map.json',\n",
       " './best_emotion_model/vocab.txt',\n",
       " './best_emotion_model/added_tokens.json',\n",
       " './best_emotion_model/tokenizer.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Model for Deployment\n",
    "\n",
    "trainer.save_model(\"./best_emotion_model\")\n",
    "tokenizer.save_pretrained(\"./best_emotion_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d055cee3-2ee0-4d8c-9fd7-104c7f3349e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload the best model later\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./best_emotion_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./best_emotion_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ec335ffc-a516-494f-a21d-8dd4a6e6a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I'm feeling really down today. → Predicted Emotion: sadness\n",
      "Text: Wow! This is amazing! → Predicted Emotion: surprise\n",
      "Text: I am so scared to go outside. → Predicted Emotion: fear\n"
     ]
    }
   ],
   "source": [
    "# Test on Custom Sentences\n",
    "\n",
    "texts = [\"I'm feeling really down today.\", \"Wow! This is amazing!\", \"I am so scared to go outside.\"]\n",
    "\n",
    "# Tokenize and predict\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits.argmax(-1)\n",
    "\n",
    "# Print predictions\n",
    "for text, pred in zip(texts, predictions):\n",
    "    print(f\"Text: {text} → Predicted Emotion: {tokenized_datasets['train'].features['label'].int2str(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1d0b447f-c80f-48ac-b05e-efd59d526d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "fear\n",
      "sadness\n",
      "surprise\n"
     ]
    }
   ],
   "source": [
    "# Extract Logits Before Applying argmax()\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict_emotion(text):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model and input to the correct device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize input text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Get model output\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        output = model(**tokens)  # Correct way to pass inputs to transformer models\n",
    "\n",
    "    # Extract logits and apply argmax to get the predicted label index\n",
    "    logits = output.logits  # Extract logits\n",
    "    prediction = torch.argmax(logits, dim=1).item()  # Get the highest probability class\n",
    "\n",
    "    # Emotion labels\n",
    "    emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "    return emotion_labels[prediction]\n",
    "\n",
    "# Example Predictions\n",
    "print(predict_emotion(\"I am feeling very happy today!\"))  # Expected: Joy\n",
    "print(predict_emotion(\"I'm so scared of what will happen next.\"))  # Expected: Fear\n",
    "print(predict_emotion(\"This is the worst day of my life.\"))  # Expected: Sadness\n",
    "print(predict_emotion(\"Wow, this is amazing!\"))  # Expected: Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0459e717-08df-4154-8245-0aaca4d0e0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5000), (2000, 5000))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Text to TF-IDF Features\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text data into TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "X_train = vectorizer.fit_transform(df_train[\"text\"])\n",
    "X_test = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# Extract labels\n",
    "y_train = df_train[\"label\"]\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "# Check shape of transformed data\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ef9f6cba-b479-44fa-a284-413bf6fe83a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "# Train & Evaluate the Support Vector Machine (SVM) on Test Data\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "svm_preds = svm_model.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_preds)\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "699b51b8-5e6d-4909-babd-b60a4c50313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.93      0.92      0.93       581\n",
      "         joy       0.88      0.95      0.91       695\n",
      "        love       0.82      0.69      0.75       159\n",
      "       anger       0.89      0.88      0.88       275\n",
      "        fear       0.85      0.86      0.86       224\n",
      "    surprise       0.74      0.56      0.64        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.85      0.81      0.83      2000\n",
      "weighted avg       0.89      0.89      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classification Report\n",
    " \n",
    "print(\"Classification Report for SVM:\")\n",
    "print(classification_report(y_test, svm_preds, target_names=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "13480c64-4f98-46e1-9590-47e5ea735d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Examples (SVM Model):\n",
      "                                                   text  label  \\\n",
      "103   i feel agitated with myself that i did not for...      4   \n",
      "1048  i wonder if the homeowners would feel weird if...      5   \n",
      "501   when we rearranged furniture in our flat and g...      3   \n",
      "1592        i have strong feelings about being faithful      2   \n",
      "575   i feel not having a generous spirit or a forgi...      2   \n",
      "625   i am feeling overwhelmed by trying to do it al...      5   \n",
      "1928  i feel inside cause life is like a game someti...      4   \n",
      "1296         i that it feels like she is being tortured      4   \n",
      "869   i feel like if people accepted that wed get al...      2   \n",
      "823   i dont remember how january was like last year...      3   \n",
      "\n",
      "      svm_predictions  \n",
      "103                 3  \n",
      "1048                4  \n",
      "501                 1  \n",
      "1592                1  \n",
      "575                 1  \n",
      "625                 4  \n",
      "1928                0  \n",
      "1296                3  \n",
      "869                 1  \n",
      "823                 0  \n"
     ]
    }
   ],
   "source": [
    "# Analyze Misclassifications for SVM\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert test data to DataFrame\n",
    "df_test_svm = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Add SVM Predictions to the DataFrame\n",
    "df_test_svm[\"svm_predictions\"] = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Show misclassified examples\n",
    "misclassified_svm = df_test_svm[df_test_svm[\"label\"] != df_test_svm[\"svm_predictions\"]]\n",
    "\n",
    "# Display random 10 misclassified examples\n",
    "print(\"Misclassified Examples (SVM Model):\")\n",
    "print(misclassified_svm.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "53d1de3a-085d-4345-95dd-0f5a92044383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Sentence Predictions (SVM):\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "SVM Prediction: joy\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "SVM Prediction: joy\n",
      "\n",
      "Sentence: I can't stop smiling, this is the best surprise ever!\n",
      "SVM Prediction: joy\n",
      "\n",
      "Sentence: I am so scared to go outside alone.\n",
      "SVM Prediction: fear\n",
      "\n",
      "Sentence: I feel so loved and appreciated today.\n",
      "SVM Prediction: love\n",
      "\n",
      "Sentence: Why do you always make me so angry?\n",
      "SVM Prediction: anger\n",
      "\n",
      "Sentence: I feel like crying all day long.\n",
      "SVM Prediction: joy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on Custom Sentences for SVM\n",
    "\n",
    "# Define custom sentences\n",
    "custom_texts = [\n",
    "    \"I am feeling very happy today!\",\n",
    "    \"This is the worst day of my life.\",\n",
    "    \"I can't stop smiling, this is the best surprise ever!\",\n",
    "    \"I am so scared to go outside alone.\",\n",
    "    \"I feel so loved and appreciated today.\",\n",
    "    \"Why do you always make me so angry?\",\n",
    "    \"I feel like crying all day long.\"\n",
    "]\n",
    "\n",
    "# Transform custom sentences using the same TF-IDF vectorizer\n",
    "custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)\n",
    "\n",
    "# Predict using SVM\n",
    "svm_custom_preds = svm_model.predict(custom_tfidf_features)\n",
    "\n",
    "# Emotion Labels Mapping\n",
    "emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "# Convert predictions to emotion labels\n",
    "svm_custom_preds_labels = [emotion_labels[pred] for pred in svm_custom_preds]\n",
    "\n",
    "# Print Predictions\n",
    "print(\"Custom Sentence Predictions (SVM):\\n\")\n",
    "for text, pred_label in zip(custom_texts, svm_custom_preds_labels):\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"SVM Prediction: {pred_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6871abff-bdef-4d1d-b922-447d7cf03f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Predictions with Logits:\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "SVM Prediction: joy\n",
      "Logits: [[ 4.21734192  5.29313949  0.75707932  2.84660651  1.83615835 -0.27445076]]\n",
      "\n",
      "Sentence: I'm so scared of what will happen next.\n",
      "SVM Prediction: fear\n",
      "Logits: [[ 4.13534549  2.99247187  0.7420411   1.8344909   5.29496232 -0.26584384]]\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "SVM Prediction: joy\n",
      "Logits: [[ 4.22671562  5.25770218  0.76205444  3.21362757  1.8341     -0.2643637 ]]\n",
      "\n",
      "Sentence: Wow, this is amazing!\n",
      "SVM Prediction: joy\n",
      "Logits: [[ 2.80986026  5.28427686 -0.27432975  1.75275479  0.74291711  4.28844537]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract Logits Before Applying argmax() to SVM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predict_emotion_svm(text):\n",
    "    \"\"\"\n",
    "    Function to predict the emotion using the trained SVM model.\n",
    "    Extracts logits (decision function values) before applying argmax().\n",
    "    \"\"\"\n",
    "    # Transform input text using the same TF-IDF vectorizer\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "\n",
    "    # Get model output (decision function for probabilities)\n",
    "    logits = svm_model.decision_function(text_tfidf)\n",
    "\n",
    "    # Apply argmax to get the predicted label index\n",
    "    prediction = np.argmax(logits)\n",
    "\n",
    "    # Emotion labels\n",
    "    emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "    return emotion_labels[prediction], logits  # Returning logits along with prediction\n",
    "\n",
    "# Example Predictions with Logits for SVM\n",
    "custom_sentences = [\n",
    "    \"I am feeling very happy today!\",  # Expected: Joy\n",
    "    \"I'm so scared of what will happen next.\",  # Expected: Fear\n",
    "    \"This is the worst day of my life.\",  # Expected: Sadness\n",
    "    \"Wow, this is amazing!\"  # Expected: Surprise\n",
    "]  \n",
    "\n",
    "# Make predictions and extract logits\n",
    "print(\"SVM Predictions with Logits:\\n\")\n",
    "for text in custom_sentences:\n",
    "    prediction, logits = predict_emotion_svm(text)\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"SVM Prediction: {prediction}\")\n",
    "    print(f\"Logits: {logits}\\n\")  # Raw model decision values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9d4134a6-051b-43f8-b13f-0083ab1045fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8725\n"
     ]
    }
   ],
   "source": [
    "# Train & Evaluate the Random Forest on Test Data\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6df9b465-4c97-47b1-ae6f-c3cbe36ed5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classification Report\n",
    "\n",
    "print(\"Classification Report for Random Forest:\")\n",
    "print(classification_report(y_test, rf_preds, target_names=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ccb12651-df78-497b-aafb-63e3a682c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Examples (Random Forest Model):\n",
      "                                                   text  label  rf_predictions\n",
      "660   i was playing a sport in an advanced pe class ...      3               1\n",
      "1530  i feel furious at love because i really though...      3               1\n",
      "1146  i feel affirmed gracious sensuous and will hav...      2               1\n",
      "119   i feel like i know who most of them are by now...      1               0\n",
      "1402                     i just keep on feeling blessed      2               1\n",
      "565   i feel like an ugly monster where i cannot sho...      0               4\n",
      "1791  i did a body scan and realized that everything...      5               1\n",
      "941   i still feel confused and guilty about the who...      4               0\n",
      "466              i feel his hand on me to stay faithful      2               1\n",
      "468                        i cant help feeling this way      0               1\n"
     ]
    }
   ],
   "source": [
    "# Analyze Misclassifications for Random Forest\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert test data to DataFrame\n",
    "df_test_rf = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Add Random Forest Predictions to the DataFrame\n",
    "df_test_rf[\"rf_predictions\"] = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Show misclassified examples\n",
    "misclassified_rf = df_test_rf[df_test_rf[\"label\"] != df_test_rf[\"rf_predictions\"]]\n",
    "\n",
    "# Display random 10 misclassified examples\n",
    "print(\"Misclassified Examples (Random Forest Model):\")\n",
    "print(misclassified_rf.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "62b62741-a46a-48fd-af22-13f10d030947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Sentence Predictions (Random Forest):\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "Random Forest Prediction: joy\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "Random Forest Prediction: joy\n",
      "\n",
      "Sentence: I can't stop smiling, this is the best surprise ever!\n",
      "Random Forest Prediction: joy\n",
      "\n",
      "Sentence: I am so scared to go outside alone.\n",
      "Random Forest Prediction: fear\n",
      "\n",
      "Sentence: I feel so loved and appreciated today.\n",
      "Random Forest Prediction: love\n",
      "\n",
      "Sentence: Why do you always make me so angry?\n",
      "Random Forest Prediction: anger\n",
      "\n",
      "Sentence: I feel like crying all day long.\n",
      "Random Forest Prediction: joy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on Custom Sentences for Random Forest\n",
    "\n",
    "# Define custom sentences\n",
    "custom_texts = [\n",
    "    \"I am feeling very happy today!\",\n",
    "    \"This is the worst day of my life.\",\n",
    "    \"I can't stop smiling, this is the best surprise ever!\",\n",
    "    \"I am so scared to go outside alone.\",\n",
    "    \"I feel so loved and appreciated today.\",\n",
    "    \"Why do you always make me so angry?\",\n",
    "    \"I feel like crying all day long.\"\n",
    "]\n",
    "\n",
    "# Transform custom sentences using the same TF-IDF vectorizer\n",
    "custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)\n",
    "\n",
    "# Predict using Random Forest\n",
    "rf_custom_preds = rf_model.predict(custom_tfidf_features)\n",
    "\n",
    "# Emotion Labels Mapping\n",
    "emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "# Convert predictions to emotion labels\n",
    "rf_custom_preds_labels = [emotion_labels[pred] for pred in rf_custom_preds]\n",
    "\n",
    "# Print Predictions\n",
    "print(\"Custom Sentence Predictions (Random Forest):\\n\")\n",
    "for text, pred_label in zip(custom_texts, rf_custom_preds_labels):\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"Random Forest Prediction: {pred_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d1be59b1-382d-44f5-9ae4-c6591b7e6aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions with Logits:\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "RF Prediction: joy\n",
      "Logits (Probabilities): [0.1  0.76 0.05 0.06 0.03 0.  ]\n",
      "\n",
      "Sentence: I'm so scared of what will happen next.\n",
      "RF Prediction: fear\n",
      "Logits (Probabilities): [0.13 0.05 0.01 0.02 0.79 0.  ]\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "RF Prediction: joy\n",
      "Logits (Probabilities): [0.2  0.53 0.03 0.1  0.13 0.01]\n",
      "\n",
      "Sentence: Wow, this is amazing!\n",
      "RF Prediction: joy\n",
      "Logits (Probabilities): [0.04 0.6  0.   0.02 0.   0.34]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract Logits Before Applying argmax() to Random Forest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predict_emotion_rf(text):\n",
    "    \"\"\"\n",
    "    Function to predict the emotion using the trained Random Forest model.\n",
    "    Extracts logits (probabilities) before applying argmax().\n",
    "    \"\"\"\n",
    "    # Transform input text using the same TF-IDF vectorizer\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "\n",
    "    # Get model output (predict_proba gives probability distribution over classes)\n",
    "    logits = rf_model.predict_proba(text_tfidf)[0]  # Extracting probabilities\n",
    "\n",
    "    # Apply argmax to get the predicted label index\n",
    "    prediction = np.argmax(logits)\n",
    "\n",
    "    # Emotion labels\n",
    "    emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "    return emotion_labels[prediction], logits  # Returning logits along with prediction\n",
    "\n",
    "# Example Predictions with Logits for Random Forest\n",
    "custom_sentences = [\n",
    "    \"I am feeling very happy today!\",  # Expected: Joy\n",
    "    \"I'm so scared of what will happen next.\",  # Expected: Fear\n",
    "    \"This is the worst day of my life.\",  # Expected: Sadness\n",
    "    \"Wow, this is amazing!\"  # Expected: Surprise\n",
    "]  \n",
    "\n",
    "# Make predictions and extract logits\n",
    "print(\"Random Forest Predictions with Logits:\\n\")\n",
    "for text in custom_sentences:\n",
    "    prediction, logits = predict_emotion_rf(text)\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"RF Prediction: {prediction}\")\n",
    "    print(f\"Logits (Probabilities): {logits}\\n\")  # Raw model probability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c3371ebe-842d-4ec4-b801-2a7d44206cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Test Accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "# Train & Evaluate the Logistic Regression Model on Test Data\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg_model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "\n",
    "# Train the model on TF-IDF features\n",
    "log_reg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on Test Data\n",
    "log_reg_preds = log_reg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_preds)\n",
    "print(f\"✅ Logistic Regression Test Accuracy: {log_reg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0f564c5f-1383-423f-9bce-0aa3390c9a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.90      0.93      0.91       581\n",
      "         joy       0.85      0.96      0.90       695\n",
      "        love       0.82      0.62      0.71       159\n",
      "       anger       0.89      0.83      0.86       275\n",
      "        fear       0.88      0.79      0.83       224\n",
      "    surprise       0.80      0.53      0.64        66\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.86      0.78      0.81      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Logistic Regression\n",
    "\n",
    "print(\"Classification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, lr_preds, target_names=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3ed4f786-6829-46e6-8652-f6b8d12c9eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Examples (Logistic Regression Model):\n",
      "                                                   text  label  \\\n",
      "433   i know that i have it nowhere near as worse as...      4   \n",
      "74    i were to go overseas or cross the border then...      2   \n",
      "1936  im polyamorous something im starting to feel t...      2   \n",
      "222   i think i wanted audiences to feel impressed i...      5   \n",
      "96    i love neglecting this blog but sometimes i fe...      2   \n",
      "715   i get to be creative if i feel like it or just...      2   \n",
      "242   i see you on the pitchers mound at our little ...      4   \n",
      "193   i really dont like quinn because i feel like s...      3   \n",
      "1387  im not sure but theres nothing that will get a...      2   \n",
      "121                        made a wonderfull new friend      1   \n",
      "\n",
      "      log_reg_predictions  \n",
      "433                     0  \n",
      "74                      1  \n",
      "1936                    1  \n",
      "222                     1  \n",
      "96                      1  \n",
      "715                     1  \n",
      "242                     0  \n",
      "193                     0  \n",
      "1387                    1  \n",
      "121                     0  \n"
     ]
    }
   ],
   "source": [
    "# Analyze Misclassifications for Logistic Regression Model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert test dataset to Pandas DataFrame\n",
    "df_test_log_reg = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Add Logistic Regression Predictions to the DataFrame\n",
    "df_test_log_reg[\"log_reg_predictions\"] = log_reg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Show misclassified examples\n",
    "misclassified_log_reg = df_test_log_reg[df_test_log_reg[\"label\"] != df_test_log_reg[\"log_reg_predictions\"]]\n",
    "\n",
    "# Display 10 randomly selected misclassified examples\n",
    "print(\"Misclassified Examples (Logistic Regression Model):\")\n",
    "print(misclassified_log_reg.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f1796e89-aaf2-41d6-a1b8-fff82c6d57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Sentence Predictions (Logistic Regression):\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "Logistic Regression Prediction: joy\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "Logistic Regression Prediction: joy\n",
      "\n",
      "Sentence: I can't stop smiling, this is the best surprise ever!\n",
      "Logistic Regression Prediction: joy\n",
      "\n",
      "Sentence: I am so scared to go outside alone.\n",
      "Logistic Regression Prediction: fear\n",
      "\n",
      "Sentence: I feel so loved and appreciated today.\n",
      "Logistic Regression Prediction: love\n",
      "\n",
      "Sentence: Why do you always make me so angry?\n",
      "Logistic Regression Prediction: anger\n",
      "\n",
      "Sentence: I feel like crying all day long.\n",
      "Logistic Regression Prediction: sadness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on Custom Sentences for Logistic Regression\n",
    "\n",
    "# Define custom sentences\n",
    "custom_texts = [\n",
    "    \"I am feeling very happy today!\",\n",
    "    \"This is the worst day of my life.\",\n",
    "    \"I can't stop smiling, this is the best surprise ever!\",\n",
    "    \"I am so scared to go outside alone.\",\n",
    "    \"I feel so loved and appreciated today.\",\n",
    "    \"Why do you always make me so angry?\",\n",
    "    \"I feel like crying all day long.\"\n",
    "]\n",
    "\n",
    "# Transform custom sentences using the same TF-IDF vectorizer\n",
    "custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)\n",
    "\n",
    "# Predict using Logistic Regression\n",
    "log_reg_custom_preds = log_reg_model.predict(custom_tfidf_features)\n",
    "\n",
    "# Emotion Labels Mapping\n",
    "emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "# Convert predictions to emotion labels\n",
    "log_reg_custom_preds_labels = [emotion_labels[pred] for pred in log_reg_custom_preds]\n",
    "\n",
    "# Print Predictions\n",
    "print(\"Custom Sentence Predictions (Logistic Regression):\\n\")\n",
    "for text, pred_label in zip(custom_texts, log_reg_custom_preds_labels):\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"Logistic Regression Prediction: {pred_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2fcc2a68-eed2-41e6-9d69-c4e5f91aa8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Predictions with Logits:\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "Logistic Regression Prediction: joy\n",
      "Logits (Probabilities): [0.07556277 0.85000386 0.01456523 0.03092256 0.02330232 0.00564325]\n",
      "\n",
      "Sentence: I'm so scared of what will happen next.\n",
      "Logistic Regression Prediction: fear\n",
      "Logits (Probabilities): [0.0754142  0.05694343 0.02117282 0.03144245 0.8017663  0.0132608 ]\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "Logistic Regression Prediction: joy\n",
      "Logits (Probabilities): [0.28885688 0.39450347 0.06980073 0.14504974 0.07739482 0.02439436]\n",
      "\n",
      "Sentence: Wow, this is amazing!\n",
      "Logistic Regression Prediction: joy\n",
      "Logits (Probabilities): [0.05419698 0.51559954 0.03195987 0.04481148 0.03571615 0.31771598]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract Logits Before Applying argmax() to Logistic Regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predict_emotion_log_reg(text):\n",
    "    \"\"\"\n",
    "    Function to predict the emotion using the trained Logistic Regression model.\n",
    "    Extracts logits (probabilities) before applying argmax().\n",
    "    \"\"\"\n",
    "    # Transform input text using the same TF-IDF vectorizer\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "\n",
    "    # Get model output (predict_proba gives probability distribution over classes)\n",
    "    logits = log_reg_model.predict_proba(text_tfidf)[0]  # Extracting probabilities\n",
    "\n",
    "    # Apply argmax to get the predicted label index\n",
    "    prediction = np.argmax(logits)\n",
    "\n",
    "    # Emotion labels\n",
    "    emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "    return emotion_labels[prediction], logits  # Returning logits along with prediction\n",
    "\n",
    "# Example Predictions with Logits for Logistic Regression\n",
    "custom_sentences = [\n",
    "    \"I am feeling very happy today!\",  # Expected: Joy\n",
    "    \"I'm so scared of what will happen next.\",  # Expected: Fear\n",
    "    \"This is the worst day of my life.\",  # Expected: Sadness\n",
    "    \"Wow, this is amazing!\"  # Expected: Surprise\n",
    "]  \n",
    "\n",
    "# Make predictions and extract logits\n",
    "print(\"Logistic Regression Predictions with Logits:\\n\")\n",
    "for text in custom_sentences:\n",
    "    prediction, logits = predict_emotion_log_reg(text)\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"Logistic Regression Prediction: {prediction}\")\n",
    "    print(f\"Logits (Probabilities): {logits}\\n\")  # Raw model probability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5087b5f6-411f-4ef1-b554-d948e523ba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model Accuracy (BERT + SVM + RF + LR): 0.8980\n"
     ]
    }
   ],
   "source": [
    "# We can now combine train & evaluate the Bert, SVM, Random Forest, and Logistic Regression using a simple majority voting for an Ensemble Approach on Test Data\n",
    "\n",
    "# Stack predictions from all models\n",
    "predictions_stack = np.column_stack((svm_preds, rf_preds, log_reg_preds, bert_preds))\n",
    "\n",
    "# Majority voting: select the most common prediction for each instance\n",
    "ensemble_preds, _ = mode(predictions_stack, axis=1)\n",
    "ensemble_preds = ensemble_preds.flatten()  # Convert to 1D array\n",
    "\n",
    "# Evaluate ensemble accuracy\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_preds)\n",
    "\n",
    "print(f\"\\nEnsemble Model Accuracy (BERT + SVM + RF + LR): {ensemble_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d70cd074-ca03-4192-80b4-2087ad75b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.93      0.96      0.94       581\n",
      "         joy       0.88      0.97      0.92       695\n",
      "        love       0.84      0.64      0.73       159\n",
      "       anger       0.93      0.87      0.90       275\n",
      "        fear       0.87      0.86      0.87       224\n",
      "    surprise       0.87      0.50      0.63        66\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.89      0.80      0.83      2000\n",
      "weighted avg       0.90      0.90      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model Classification Report (Bert, SVM, Random Forest, and Logistic Regression)\n",
    "\n",
    "print(\"\\nEnsemble Model Classification Report:\")\n",
    "print(classification_report(y_test, ensemble_preds, target_names=[\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "70ceea88-5cc1-43b6-9473-8c25aa566989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Examples (Ensemble Model - BERT + SVM + RF + Logistic Regression):\n",
      "                                                   text  label  \\\n",
      "693   i can say is that as long as you enjoy the sto...      0   \n",
      "1533  i actually was in a meeting last week where so...      3   \n",
      "1714           i also do feel passionate about teaching      2   \n",
      "206   i wish to know whether i should feel sympathet...      2   \n",
      "476   i feel quite helpless in all of this so prayer...      0   \n",
      "254   i feel blessed beyond blessed to share my life...      2   \n",
      "1467  i seek out pain to feel tortured just to feel ...      4   \n",
      "433   i know that i have it nowhere near as worse as...      4   \n",
      "828      i feel unprotected even while travelling alone      4   \n",
      "861   i feel assaulted by this shit storm of confusi...      4   \n",
      "\n",
      "      ensemble_predictions  \n",
      "693                      3  \n",
      "1533                     0  \n",
      "1714                     1  \n",
      "206                      1  \n",
      "476                      4  \n",
      "254                      1  \n",
      "1467                     3  \n",
      "433                      0  \n",
      "828                      0  \n",
      "861                      0  \n"
     ]
    }
   ],
   "source": [
    "# Analyze Misclassifications for Ensemble Model (Bert, SVM, Random Forest, and Logistic Regression)\n",
    "\n",
    "# Convert test dataset to Pandas DataFrame\n",
    "df_test_ensemble = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# Get predictions from individual models\n",
    "svm_preds = svm_model.predict(X_test_tfidf)\n",
    "rf_preds = rf_model.predict(X_test_tfidf)\n",
    "log_reg_preds = log_reg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Get predictions from the BERT model\n",
    "bert_preds = trainer.predict(tokenized_datasets[\"test\"]).predictions.argmax(-1)\n",
    "\n",
    "# Perform Majority Voting for Ensemble Prediction\n",
    "ensemble_preds = np.array([svm_preds, rf_preds, log_reg_preds, bert_preds])  # Stack predictions\n",
    "final_ensemble_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=ensemble_preds)\n",
    "\n",
    "# Add Ensemble Predictions to the DataFrame\n",
    "df_test_ensemble[\"ensemble_predictions\"] = final_ensemble_preds\n",
    "\n",
    "# Show misclassified examples\n",
    "misclassified_ensemble = df_test_ensemble[df_test_ensemble[\"label\"] != df_test_ensemble[\"ensemble_predictions\"]]\n",
    "\n",
    "# Display 10 randomly selected misclassified examples\n",
    "print(\"Misclassified Examples (Ensemble Model - BERT + SVM + RF + Logistic Regression):\")\n",
    "print(misclassified_ensemble.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "370b9156-c395-4a5a-b22e-0a1d538d8495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Sentence Predictions (Ensemble Model - BERT + SVM + RF + Logistic Regression):\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "Ensemble Model Prediction: joy\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "Ensemble Model Prediction: joy\n",
      "\n",
      "Sentence: I can't stop smiling, this is the best surprise ever!\n",
      "Ensemble Model Prediction: joy\n",
      "\n",
      "Sentence: I am so scared to go outside alone.\n",
      "Ensemble Model Prediction: fear\n",
      "\n",
      "Sentence: I feel so loved and appreciated today.\n",
      "Ensemble Model Prediction: love\n",
      "\n",
      "Sentence: Why do you always make me so angry?\n",
      "Ensemble Model Prediction: anger\n",
      "\n",
      "Sentence: I feel like crying all day long.\n",
      "Ensemble Model Prediction: sadness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on Custom Sentences for Ensemble Model (Bert, SVM, Random Forest, and Logistic Regression)\n",
    "\n",
    "# Define custom sentences\n",
    "custom_texts = [\n",
    "    \"I am feeling very happy today!\",\n",
    "    \"This is the worst day of my life.\",\n",
    "    \"I can't stop smiling, this is the best surprise ever!\",\n",
    "    \"I am so scared to go outside alone.\",\n",
    "    \"I feel so loved and appreciated today.\",\n",
    "    \"Why do you always make me so angry?\",\n",
    "    \"I feel like crying all day long.\"\n",
    "]\n",
    "\n",
    "# Transform custom sentences using the same TF-IDF vectorizer for ML models\n",
    "custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)\n",
    "\n",
    "# Get predictions from ML models\n",
    "svm_custom_preds = svm_model.predict(custom_tfidf_features)\n",
    "rf_custom_preds = rf_model.predict(custom_tfidf_features)\n",
    "log_reg_custom_preds = log_reg_model.predict(custom_tfidf_features)\n",
    "\n",
    "# Get predictions from the BERT model\n",
    "custom_tokenized_inputs = tokenizer(custom_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "custom_tokenized_inputs = {k: v.to(model.device) for k, v in custom_tokenized_inputs.items()}  # Move to device\n",
    "\n",
    "with torch.no_grad():\n",
    "    bert_logits = model(**custom_tokenized_inputs).logits\n",
    "    bert_custom_preds = bert_logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Perform Majority Voting for Ensemble Prediction\n",
    "ensemble_preds = np.array([svm_custom_preds, rf_custom_preds, log_reg_custom_preds, bert_custom_preds])  # Stack predictions\n",
    "final_ensemble_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=ensemble_preds)\n",
    "\n",
    "# Emotion Labels Mapping\n",
    "emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "# Convert predictions to emotion labels\n",
    "ensemble_custom_preds_labels = [emotion_labels[pred] for pred in final_ensemble_preds]\n",
    "\n",
    "# Print Predictions\n",
    "print(\"Custom Sentence Predictions (Ensemble Model - BERT + SVM + RF + Logistic Regression):\\n\")\n",
    "for text, pred_label in zip(custom_texts, ensemble_custom_preds_labels):\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"Ensemble Model Prediction: {pred_label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9b1a1b4f-5754-47ed-bb8d-038c4670baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Predictions with Logits (BERT + SVM + RF + Logistic Regression):\n",
      "\n",
      "Sentence: I am feeling very happy today!\n",
      "Ensemble Model Prediction: joy\n",
      "Logits (Averaged Probabilities): [-0.2570371   2.38853983 -0.20290386 -0.38366643 -0.37555413 -0.28720264]\n",
      "\n",
      "Sentence: I'm so scared of what will happen next.\n",
      "Ensemble Model Prediction: fear\n",
      "Logits (Averaged Probabilities): [-0.37362869 -0.38495599 -0.35005543 -0.26266308  2.23493997 -0.2599686 ]\n",
      "\n",
      "Sentence: This is the worst day of my life.\n",
      "Ensemble Model Prediction: sadness\n",
      "Logits (Averaged Probabilities): [ 1.6625196  -0.12750439 -0.57734552  0.55725768 -0.1043694  -0.63198028]\n",
      "\n",
      "Sentence: Wow, this is amazing!\n",
      "Ensemble Model Prediction: surprise\n",
      "Logits (Averaged Probabilities): [-0.38694778  0.86072292 -0.3691757  -0.37401361 -0.01579849  1.4125763 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract Logits Before Applying argmax() to Ensemble Model (Bert, SVM + Random Forest + Logistic Regression)\n",
    "\n",
    "def predict_emotion_ensemble(text):\n",
    "    \"\"\"\n",
    "    Function to predict the emotion using the Ensemble Model (BERT + SVM + RF + Logistic Regression).\n",
    "    Extracts logits (probabilities/decision function values) before applying argmax().\n",
    "    \"\"\"\n",
    "    # Transform input text using the same TF-IDF vectorizer for ML models\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "\n",
    "    # Get model outputs (probabilities/logits)\n",
    "    svm_logits = svm_model.decision_function(text_tfidf)  # Decision function values for SVM\n",
    "    rf_logits = rf_model.predict_proba(text_tfidf)[0]  # Probabilities for Random Forest\n",
    "    log_reg_logits = log_reg_model.predict_proba(text_tfidf)[0]  # Probabilities for Logistic Regression\n",
    "\n",
    "    # Get logits from BERT model\n",
    "    tokenized_text = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    tokenized_text = {k: v.to(model.device) for k, v in tokenized_text.items()}  # Move to device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bert_logits = model(**tokenized_text).logits.cpu().numpy()[0]  # Extract logits from BERT\n",
    "\n",
    "    # Normalize SVM logits to match probability scale\n",
    "    svm_probs = np.exp(svm_logits) / np.sum(np.exp(svm_logits), axis=1, keepdims=True)\n",
    "\n",
    "    # Average the logits for final ensemble decision\n",
    "    ensemble_logits = (svm_probs[0] + rf_logits + log_reg_logits + bert_logits) / 4  # Averaging\n",
    "\n",
    "    # Apply argmax to get the predicted label index\n",
    "    prediction = np.argmax(ensemble_logits)\n",
    "\n",
    "    # Emotion labels\n",
    "    emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "    return emotion_labels[prediction], ensemble_logits  # Returning logits along with prediction\n",
    "\n",
    "# Example Predictions with Logits for Ensemble Model\n",
    "custom_sentences = [\n",
    "    \"I am feeling very happy today!\",  # Expected: Joy\n",
    "    \"I'm so scared of what will happen next.\",  # Expected: Fear\n",
    "    \"This is the worst day of my life.\",  # Expected: Sadness\n",
    "    \"Wow, this is amazing!\"  # Expected: Surprise\n",
    "]  \n",
    "\n",
    "# Make predictions and extract logits\n",
    "print(\"Ensemble Model Predictions with Logits (BERT + SVM + RF + Logistic Regression):\\n\")\n",
    "for text in custom_sentences:\n",
    "    prediction, logits = predict_emotion_ensemble(text)\n",
    "    print(f\"Sentence: {text}\")\n",
    "    print(f\"Ensemble Model Prediction: {prediction}\")\n",
    "    print(f\"Logits (Averaged Probabilities): {logits}\\n\")  # Raw model decision values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024bf34-2da5-4b8f-bc54-623fd239c34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
