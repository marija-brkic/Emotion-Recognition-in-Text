


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.tokenize import word_tokenize
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from nltk.corpus import stopwords
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split


from google.colab import drive
drive.mount('/content/drive')
dataset_path = '/content/drive/MyDrive/Colab Notebooks/HONLP/train-00000-of-00001.parquet'



nltk.download("stopwords")
nltk.download("punkt")
nltk.download('punkt_tab')
sns.set_style("darkgrid")
sns.set_context("notebook")
pd.set_option('display.precision', 2)





df = pd.read_parquet(dataset_path)


print(df.info())
df.head(5)


labels = {
    0: 'sadness',
    1: 'joy',
    2: 'love',
    3: 'anger',
    4: 'fear',
    5: 'surprise'
}


class_counts = df["label"].value_counts().sort_index()

plt.figure(figsize=(6, 4))
bars = plt.bar(class_counts.index.map(labels), class_counts.values, color=["blue", "orange", "green"])

for bar in bars:
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(bar.get_height()),
             ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')

plt.xlabel("Emotion")
plt.ylabel("Number of Tweets")
plt.title("Number of Tweets per Emotion")
plt.xticks(rotation=0)
plt.show()





df["char_count"] = df["text"].apply(lambda x: len(x))

print(df["char_count"].describe())

plt.figure(figsize=(8, 5))
plt.hist(df["char_count"], bins=30, color="skyblue", edgecolor="black")
plt.xlabel("Char Count per Tweet")
plt.ylabel("Frequency")
plt.title("Distribution of Char Counts per Tweet")
plt.show()



char_counts_per_class = [df[df["label"] == label]["char_count"] for label in sorted(df["label"].unique())]

class_labels = [labels[label] for label in sorted(df["label"].unique())]

plt.figure(figsize=(8, 5))
plt.boxplot(char_counts_per_class, labels=class_labels, patch_artist=True, boxprops=dict(facecolor="lightblue"))
plt.xlabel("Emotion")
plt.ylabel("Character Count")
plt.title("Character Count Distribution per Emotion")
plt.show()



longest_tweets = df[df["char_count"]>400]
for _, row in longest_tweets.iterrows():
    print("\nTweet:\n")
    print(labels[row["label"]])
    print("\n")
    print(row["text"])





df = df[df["char_count"]<=400]


char_counts_per_class = [df[df["label"] == label]["char_count"] for label in sorted(df["label"].unique())]

class_labels = [labels[label] for label in sorted(df["label"].unique())]

plt.figure(figsize=(8, 5))
plt.boxplot(char_counts_per_class, labels=class_labels, patch_artist=True, boxprops=dict(facecolor="lightblue"))
plt.xlabel("Emotion")
plt.ylabel("Character Count")
plt.title("Character Count Distribution per Emotion")
plt.show()


df['tokens'] = df['text'].apply(word_tokenize)
df.head(5)


df['types'] = df.tokens.map(set)
df['types_count'] = df.types.map(len)
df.head(5)


types_counts_per_class = [df[df["label"] == label]["types_count"] for label in sorted(df["label"].unique())]

class_labels = [labels[label] for label in sorted(df["label"].unique())]

plt.figure(figsize=(8, 5))
plt.boxplot(types_counts_per_class, labels=class_labels, patch_artist=True, boxprops=dict(facecolor="lightblue"))
plt.xlabel("Emotion")
plt.ylabel("Vocabulary Length")
plt.title("Vocabulary Length Distribution per Emotion")
plt.show()





uniq_per_class = [df[df["label"] == label]["types_count"]/len(df[df["label"] == label]["types"]) for label in sorted(df["label"].unique())]

class_labels = [labels[label] for label in sorted(df["label"].unique())]

plt.figure(figsize=(8, 5))
plt.boxplot(uniq_per_class, labels=class_labels, patch_artist=True, boxprops=dict(facecolor="lightblue"))
plt.xlabel("Emotion")
plt.ylabel("Vocabulary Uniquness")
plt.title("Vocabulary Uniquness Distribution per Emotion")
plt.show()





all_tokens = [word for tokens in df["tokens"] for word in tokens]
token_freq = Counter(all_tokens)
token_df = pd.DataFrame(token_freq.items(), columns=["token", "frequency"])
token_df = token_df.sort_values(by="frequency", ascending=False).reset_index(drop=True)
token_df



import string

def count_punctuation(tokens):
    return sum(1 for token in tokens if token in string.punctuation)

punctuations = df["tokens"].apply(count_punctuation)

print(punctuations.unique())














vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features = 1000)
xs_tf_idf = vectorizer.fit_transform(df.text).toarray()



X_train, X_test, y_train, y_test = train_test_split(xs_tf_idf, df['label'], test_size=0.2, random_state=42)

pca = PCA(n_components=2)
reduced_data_pca_train = pca.fit_transform(X_train)

reduced_data_pca_test = pca.transform(X_test)


plt.figure(figsize=(8, 5))
scatter = plt.scatter(reduced_data_pca_train[:, 0], reduced_data_pca_train[:, 1], c=y_train, cmap='viridis', alpha=0.6)

plt.title("PCA-Without removing stop words, with unigrams")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")

plt.legend(handles=scatter.legend_elements()[0], labels=[str(i) for i in sorted(y_train.unique())], title="Classes")

plt.show()






vectorizer_sw = TfidfVectorizer(ngram_range=(1,1), stop_words = "english", max_features = 1000)
xs_tf_idf_sw = vectorizer_sw.fit_transform(df.text).toarray()


X_train_sw, X_test_sw, y_train_sw, y_test_sw = train_test_split(xs_tf_idf_sw, df['label'], test_size=0.2, random_state=42)

pca = PCA(n_components=2)
reduced_data_pca_train_sw = pca.fit_transform(X_train_sw)

reduced_data_pca_test_sw = pca.transform(X_test_sw)


plt.figure(figsize=(8, 5))
scatter = plt.scatter(reduced_data_pca_train_sw[:, 0], reduced_data_pca_train_sw[:, 1], c=y_train_sw, cmap='viridis', alpha=0.6)

plt.title("PCA-With removing stop words, with unigrams")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")

plt.legend(handles=scatter.legend_elements()[0], labels=[str(i) for i in sorted(y_train_sw.unique())], title="Classes")

plt.show()





pca = PCA(n_components=100)
X_train_sw = pca.fit_transform(X_train_sw)
X_test_sw = pca.transform(X_test_sw)





X_train_sw, X_val_sw, y_train_sw, y_val_sw = train_test_split(X_train_sw, y_train_sw, test_size=0.2, random_state=42)





X_train_sw_reshaped = X_train_sw.reshape(X_train_sw.shape[0], X_train_sw.shape[1], 1)
X_test_sw_reshaped = X_test_sw.reshape(X_test_sw.shape[0], X_test_sw.shape[1], 1)
X_val_sw_reshaped = X_val_sw.reshape(X_val_sw.shape[0], X_val_sw.shape[1], 1)


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Embedding
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight


class_weight_dict = compute_class_weight('balanced', classes=np.unique(y_train_sw), y=y_train_sw)
class_weight_dict = dict(enumerate(class_weight_dict))


X_train_sw_reshaped.shape


model = Sequential([
    Conv1D(128, 3, activation='relu', input_shape=(X_train_sw_reshaped.shape[1], X_train_sw_reshaped.shape[2])),
    MaxPooling1D(pool_size=2),

    Conv1D(64, 3, activation='relu'),
    MaxPooling1D(pool_size=2),

    Conv1D(32, 3, activation='relu'),
    MaxPooling1D(pool_size=2),

    Flatten(),

    Dense(32, activation='relu'),
    Dropout(0.5),

    Dense(len(np.unique(y_train_sw)), activation='softmax')
])



model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)


history = model.fit(X_train_sw_reshaped, y_train_sw,
                    epochs=20,
                    batch_size=32,
                    validation_data=(X_val_sw_reshaped, y_val_sw),
                    class_weight=class_weight_dict,
                    callbacks=[early_stopping],
                    verbose=1
                    )





vectorizer_sw = TfidfVectorizer(ngram_range=(1,1), stop_words = "english", max_features = 5000)
xs_tf_idf_sw = vectorizer_sw.fit_transform(df.text).toarray()
X_train_sw, X_test_sw, y_train_sw, y_test_sw = train_test_split(xs_tf_idf_sw, df['label'], test_size=0.2, random_state=42)
X_train_sw, X_val_sw, y_train_sw, y_val_sw = train_test_split(X_train_sw, y_train_sw, test_size=0.2, random_state=42)


X_train_sw_reshaped = X_train_sw.reshape(X_train_sw.shape[0], X_train_sw.shape[1], 1)
X_test_sw_reshaped = X_test_sw.reshape(X_test_sw.shape[0], X_test_sw.shape[1], 1)
X_val_sw_reshaped = X_val_sw.reshape(X_val_sw.shape[0], X_val_sw.shape[1], 1)


class_weight_dict = compute_class_weight('balanced', classes=np.unique(y_train_sw), y=y_train_sw)
class_weight_dict = dict(enumerate(class_weight_dict))


model = Sequential([
    Conv1D(128, 3, activation='relu', input_shape=(X_train_sw_reshaped.shape[1], X_train_sw_reshaped.shape[2])),
    MaxPooling1D(pool_size=2),

    Conv1D(64, 3, activation='relu'),
    MaxPooling1D(pool_size=2),

    Conv1D(32, 3, activation='relu'),
    MaxPooling1D(pool_size=2),

    Conv1D(16, 3, activation='relu'),
    MaxPooling1D(pool_size=2),

    Flatten(),

    Dense(32, activation='relu'),
    Dropout(0.5),

    Dense(len(np.unique(y_train_sw)), activation='softmax')
])


model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)


history = model.fit(X_train_sw_reshaped, y_train_sw,
                    epochs=20,
                    batch_size=32,
                    validation_data=(X_val_sw_reshaped, y_val_sw),
                    class_weight=class_weight_dict,
                    callbacks=[early_stopping],
                    verbose=1
                    )


y_pred = model.predict(X_test_sw_reshaped)
y_pred_classes = np.argmax(y_pred, axis=1)


from sklearn.metrics import classification_report, confusion_matrix


print(classification_report(y_test_sw, y_pred_classes))





conf_matrix = confusion_matrix(y_test_sw, y_pred_classes)

labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']

plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()









misclassified_idx = np.where(y_test_sw != y_pred_classes)[0]

for i in range(5):
    idx = misclassified_idx[i]
    print(f"Text: {df.text.iloc[idx]}")
    print(f"True Label: {labels[y_test_sw.iloc[idx]]}")
    print(f"Predicted Label: {labels[y_pred_classes[idx]]}")
    print("-" * 80)











# Load the Dataset

from datasets import load_dataset

# Load the emotion dataset
dataset = load_dataset("dair-ai/emotion")




# BERT-based transformers model

from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load pre-trained model and tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=6)


# Tokenize the Data

from transformers import AutoTokenizer

# Load the tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Tokenization function
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Apply tokenization
tokenized_datasets = dataset.map(tokenize_function, batched=True)

# Print a sample
print(tokenized_datasets["train"][0])


# Handle Class Imbalance

from collections import Counter
import torch

# Count label distribution in training data
labels = dataset["train"]["label"]
label_counts = Counter(labels)

# Compute class weights
num_samples = len(labels)
num_classes = len(label_counts)
class_weights = [num_samples / (num_classes * count) for count in label_counts.values()]
class_weights_tensor = torch.tensor(class_weights)

print(f"Class Weights: {class_weights}")


# Define Training Arguments & Trainer

from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",  # Evaluate after every epoch
    save_strategy="epoch",  # Save best model at the end
    learning_rate=1e-5,  # Lower learning rate improves generalization
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=5,  # Train for longer
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
)


# Train the model

trainer.train()


# Evaluate the Model on Test Data

import evaluate

# Load accuracy metric
metric = evaluate.load("accuracy")

# Get model predictions
predictions = trainer.predict(tokenized_datasets["test"])
preds = predictions.predictions.argmax(-1)

# Compute accuracy
accuracy = metric.compute(predictions=preds, references=tokenized_datasets["test"]["label"])
print(f"Test Accuracy: {accuracy['accuracy']:.4f}")


# Improve Model Generalization (Fix Overfitting)

from transformers import EarlyStoppingCallback

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]  # Stop if no improvement after 1 epoch
)


# Apply Dropout Regularization in the model

from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=6, hidden_dropout_prob=0.3)


# Analyze Model Errors (Classification Report)

from sklearn.metrics import classification_report

labels = tokenized_datasets["test"]["label"]
print(classification_report(labels, preds, target_names=["sadness", "joy", "love", "anger", "fear", "surprise"]))


# Analyze Misclassifications

import pandas as pd

# Convert test data to DataFrame
df_test = dataset["test"].to_pandas()
df_test["predictions"] = preds

# Show misclassified examples
misclassified = df_test[df_test["label"] != df_test["predictions"]]
print(misclassified.sample(10))


# Save the Model for Deployment

trainer.save_model("./best_emotion_model")
tokenizer.save_pretrained("./best_emotion_model")


# To reload the best model later

from transformers import AutoModelForSequenceClassification, AutoTokenizer

model = AutoModelForSequenceClassification.from_pretrained("./best_emotion_model")
tokenizer = AutoTokenizer.from_pretrained("./best_emotion_model")


# Test on Custom Sentences

texts = ["I'm feeling really down today.", "Wow! This is amazing!", "I am so scared to go outside."]

# Tokenize and predict
inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
outputs = model(**inputs)
predictions = outputs.logits.argmax(-1)

# Print predictions
for text, pred in zip(texts, predictions):
    print(f"Text: {text} → Predicted Emotion: {tokenized_datasets['train'].features['label'].int2str(pred.item())}")


# Extract Logits Before Applying argmax()

import torch

def predict_emotion(text):
    # Ensure the model is in evaluation mode
    model.eval()
    
    # Move model and input to the correct device (GPU or CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    # Tokenize input text
    tokens = tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(device)

    # Get model output
    with torch.no_grad():  # Disable gradient calculations for inference
        output = model(**tokens)  # Correct way to pass inputs to transformer models

    # Extract logits and apply argmax to get the predicted label index
    logits = output.logits  # Extract logits
    prediction = torch.argmax(logits, dim=1).item()  # Get the highest probability class

    # Emotion labels
    emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

    return emotion_labels[prediction]

# Example Predictions
print(predict_emotion("I am feeling very happy today!"))  # Expected: Joy
print(predict_emotion("I'm so scared of what will happen next."))  # Expected: Fear
print(predict_emotion("This is the worst day of my life."))  # Expected: Sadness
print(predict_emotion("Wow, this is amazing!"))  # Expected: Surprise


# Convert Text to TF-IDF Features

from sklearn.feature_extraction.text import TfidfVectorizer

# Convert text data into TF-IDF vectors
vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency
X_train = vectorizer.fit_transform(df_train["text"])
X_test = vectorizer.transform(df_test["text"])

# Extract labels
y_train = df_train["label"]
y_test = df_test["label"]




# Train & Evaluate the Support Vector Machine (SVM) on Test Data

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Train SVM model
svm_model = SVC(kernel="linear")
svm_model.fit(X_train, y_train)

# Predict and evaluate
svm_preds = svm_model.predict(X_test)
svm_acc = accuracy_score(y_test, svm_preds)

print(f"SVM Accuracy: {svm_acc:.4f}")


# SVM Classification Report
 
print("Classification Report for SVM:")
print(classification_report(y_test, svm_preds, target_names=["sadness", "joy", "love", "anger", "fear", "surprise"]))


# Analyze Misclassifications for SVM

import pandas as pd

# Convert test data to DataFrame
df_test_svm = dataset["test"].to_pandas()

# Add SVM Predictions to the DataFrame
df_test_svm["svm_predictions"] = svm_model.predict(X_test_tfidf)

# Show misclassified examples
misclassified_svm = df_test_svm[df_test_svm["label"] != df_test_svm["svm_predictions"]]

# Display random 10 misclassified examples
print("Misclassified Examples (SVM Model):")
print(misclassified_svm.sample(10))


# Test on Custom Sentences for SVM

# Define custom sentences
custom_texts = [
    "I am feeling very happy today!",
    "This is the worst day of my life.",
    "I can't stop smiling, this is the best surprise ever!",
    "I am so scared to go outside alone.",
    "I feel so loved and appreciated today.",
    "Why do you always make me so angry?",
    "I feel like crying all day long."
]

# Transform custom sentences using the same TF-IDF vectorizer
custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)

# Predict using SVM
svm_custom_preds = svm_model.predict(custom_tfidf_features)

# Emotion Labels Mapping
emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

# Convert predictions to emotion labels
svm_custom_preds_labels = [emotion_labels[pred] for pred in svm_custom_preds]

# Print Predictions
print("Custom Sentence Predictions (SVM):\n")
for text, pred_label in zip(custom_texts, svm_custom_preds_labels):
    print(f"Sentence: {text}")
    print(f"SVM Prediction: {pred_label}\n")


# Extract Logits Before Applying argmax() to SVM

import numpy as np

def predict_emotion_svm(text):
    """
    Function to predict the emotion using the trained SVM model.
    Extracts logits (decision function values) before applying argmax().
    """
    # Transform input text using the same TF-IDF vectorizer
    text_tfidf = tfidf_vectorizer.transform([text])

    # Get model output (decision function for probabilities)
    logits = svm_model.decision_function(text_tfidf)

    # Apply argmax to get the predicted label index
    prediction = np.argmax(logits)

    # Emotion labels
    emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

    return emotion_labels[prediction], logits  # Returning logits along with prediction

# Example Predictions with Logits for SVM
custom_sentences = [
    "I am feeling very happy today!",  # Expected: Joy
    "I'm so scared of what will happen next.",  # Expected: Fear
    "This is the worst day of my life.",  # Expected: Sadness
    "Wow, this is amazing!"  # Expected: Surprise
]  

# Make predictions and extract logits
print("SVM Predictions with Logits:\n")
for text in custom_sentences:
    prediction, logits = predict_emotion_svm(text)
    print(f"Sentence: {text}")
    print(f"SVM Prediction: {prediction}")
    print(f"Logits: {logits}\n")  # Raw model decision values


# Train & Evaluate the Random Forest on Test Data

from sklearn.ensemble import RandomForestClassifier

# Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict and evaluate
rf_preds = rf_model.predict(X_test)
rf_acc = accuracy_score(y_test, rf_preds)

print(f"Random Forest Accuracy: {rf_acc:.4f}")


# Random Forest Classification Report

print("Classification Report for Random Forest:")
print(classification_report(y_test, rf_preds, target_names=["sadness", "joy", "love", "anger", "fear", "surprise"]))


# Analyze Misclassifications for Random Forest

import pandas as pd

# Convert test data to DataFrame
df_test_rf = dataset["test"].to_pandas()

# Add Random Forest Predictions to the DataFrame
df_test_rf["rf_predictions"] = rf_model.predict(X_test_tfidf)

# Show misclassified examples
misclassified_rf = df_test_rf[df_test_rf["label"] != df_test_rf["rf_predictions"]]

# Display random 10 misclassified examples
print("Misclassified Examples (Random Forest Model):")
print(misclassified_rf.sample(10))


# Test on Custom Sentences for Random Forest

# Define custom sentences
custom_texts = [
    "I am feeling very happy today!",
    "This is the worst day of my life.",
    "I can't stop smiling, this is the best surprise ever!",
    "I am so scared to go outside alone.",
    "I feel so loved and appreciated today.",
    "Why do you always make me so angry?",
    "I feel like crying all day long."
]

# Transform custom sentences using the same TF-IDF vectorizer
custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)

# Predict using Random Forest
rf_custom_preds = rf_model.predict(custom_tfidf_features)

# Emotion Labels Mapping
emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

# Convert predictions to emotion labels
rf_custom_preds_labels = [emotion_labels[pred] for pred in rf_custom_preds]

# Print Predictions
print("Custom Sentence Predictions (Random Forest):\n")
for text, pred_label in zip(custom_texts, rf_custom_preds_labels):
    print(f"Sentence: {text}")
    print(f"Random Forest Prediction: {pred_label}\n")


# Extract Logits Before Applying argmax() to Random Forest

import numpy as np

def predict_emotion_rf(text):
    """
    Function to predict the emotion using the trained Random Forest model.
    Extracts logits (probabilities) before applying argmax().
    """
    # Transform input text using the same TF-IDF vectorizer
    text_tfidf = tfidf_vectorizer.transform([text])

    # Get model output (predict_proba gives probability distribution over classes)
    logits = rf_model.predict_proba(text_tfidf)[0]  # Extracting probabilities

    # Apply argmax to get the predicted label index
    prediction = np.argmax(logits)

    # Emotion labels
    emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

    return emotion_labels[prediction], logits  # Returning logits along with prediction

# Example Predictions with Logits for Random Forest
custom_sentences = [
    "I am feeling very happy today!",  # Expected: Joy
    "I'm so scared of what will happen next.",  # Expected: Fear
    "This is the worst day of my life.",  # Expected: Sadness
    "Wow, this is amazing!"  # Expected: Surprise
]  

# Make predictions and extract logits
print("Random Forest Predictions with Logits:\n")
for text in custom_sentences:
    prediction, logits = predict_emotion_rf(text)
    print(f"Sentence: {text}")
    print(f"RF Prediction: {prediction}")
    print(f"Logits (Probabilities): {logits}\n")  # Raw model probability values


# Train & Evaluate the Logistic Regression Model on Test Data

# Initialize Logistic Regression model
log_reg_model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)

# Train the model on TF-IDF features
log_reg_model.fit(X_train_tfidf, y_train)

# Predict on Test Data
log_reg_preds = log_reg_model.predict(X_test_tfidf)

# Evaluate the model
log_reg_accuracy = accuracy_score(y_test, log_reg_preds)
print(f"✅ Logistic Regression Test Accuracy: {log_reg_accuracy:.4f}")


# Classification Report for Logistic Regression

print("Classification Report for Logistic Regression:")
print(classification_report(y_test, lr_preds, target_names=["sadness", "joy", "love", "anger", "fear", "surprise"]))


# Analyze Misclassifications for Logistic Regression Model

import pandas as pd

# Convert test dataset to Pandas DataFrame
df_test_log_reg = dataset["test"].to_pandas()

# Add Logistic Regression Predictions to the DataFrame
df_test_log_reg["log_reg_predictions"] = log_reg_model.predict(X_test_tfidf)

# Show misclassified examples
misclassified_log_reg = df_test_log_reg[df_test_log_reg["label"] != df_test_log_reg["log_reg_predictions"]]

# Display 10 randomly selected misclassified examples
print("Misclassified Examples (Logistic Regression Model):")
print(misclassified_log_reg.sample(10))


# Test on Custom Sentences for Logistic Regression

# Define custom sentences
custom_texts = [
    "I am feeling very happy today!",
    "This is the worst day of my life.",
    "I can't stop smiling, this is the best surprise ever!",
    "I am so scared to go outside alone.",
    "I feel so loved and appreciated today.",
    "Why do you always make me so angry?",
    "I feel like crying all day long."
]

# Transform custom sentences using the same TF-IDF vectorizer
custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)

# Predict using Logistic Regression
log_reg_custom_preds = log_reg_model.predict(custom_tfidf_features)

# Emotion Labels Mapping
emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

# Convert predictions to emotion labels
log_reg_custom_preds_labels = [emotion_labels[pred] for pred in log_reg_custom_preds]

# Print Predictions
print("Custom Sentence Predictions (Logistic Regression):\n")
for text, pred_label in zip(custom_texts, log_reg_custom_preds_labels):
    print(f"Sentence: {text}")
    print(f"Logistic Regression Prediction: {pred_label}\n")


# Extract Logits Before Applying argmax() to Logistic Regression

import numpy as np

def predict_emotion_log_reg(text):
    """
    Function to predict the emotion using the trained Logistic Regression model.
    Extracts logits (probabilities) before applying argmax().
    """
    # Transform input text using the same TF-IDF vectorizer
    text_tfidf = tfidf_vectorizer.transform([text])

    # Get model output (predict_proba gives probability distribution over classes)
    logits = log_reg_model.predict_proba(text_tfidf)[0]  # Extracting probabilities

    # Apply argmax to get the predicted label index
    prediction = np.argmax(logits)

    # Emotion labels
    emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

    return emotion_labels[prediction], logits  # Returning logits along with prediction

# Example Predictions with Logits for Logistic Regression
custom_sentences = [
    "I am feeling very happy today!",  # Expected: Joy
    "I'm so scared of what will happen next.",  # Expected: Fear
    "This is the worst day of my life.",  # Expected: Sadness
    "Wow, this is amazing!"  # Expected: Surprise
]  

# Make predictions and extract logits
print("Logistic Regression Predictions with Logits:\n")
for text in custom_sentences:
    prediction, logits = predict_emotion_log_reg(text)
    print(f"Sentence: {text}")
    print(f"Logistic Regression Prediction: {prediction}")
    print(f"Logits (Probabilities): {logits}\n")  # Raw model probability values


# We can now combine train & evaluate the Bert, SVM, Random Forest, and Logistic Regression using a simple majority voting for an Ensemble Approach on Test Data

# Stack predictions from all models
predictions_stack = np.column_stack((svm_preds, rf_preds, log_reg_preds, bert_preds))

# Majority voting: select the most common prediction for each instance
ensemble_preds, _ = mode(predictions_stack, axis=1)
ensemble_preds = ensemble_preds.flatten()  # Convert to 1D array

# Evaluate ensemble accuracy
ensemble_acc = accuracy_score(y_test, ensemble_preds)

print(f"\nEnsemble Model Accuracy (BERT + SVM + RF + LR): {ensemble_acc:.4f}")


# Ensemble Model Classification Report (Bert, SVM, Random Forest, and Logistic Regression)

print("\nEnsemble Model Classification Report:")
print(classification_report(y_test, ensemble_preds, target_names=["sadness", "joy", "love", "anger", "fear", "surprise"]))


# Analyze Misclassifications for Ensemble Model (Bert, SVM, Random Forest, and Logistic Regression)

# Convert test dataset to Pandas DataFrame
df_test_ensemble = dataset["test"].to_pandas()

# Get predictions from individual models
svm_preds = svm_model.predict(X_test_tfidf)
rf_preds = rf_model.predict(X_test_tfidf)
log_reg_preds = log_reg_model.predict(X_test_tfidf)

# Get predictions from the BERT model
bert_preds = trainer.predict(tokenized_datasets["test"]).predictions.argmax(-1)

# Perform Majority Voting for Ensemble Prediction
ensemble_preds = np.array([svm_preds, rf_preds, log_reg_preds, bert_preds])  # Stack predictions
final_ensemble_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=ensemble_preds)

# Add Ensemble Predictions to the DataFrame
df_test_ensemble["ensemble_predictions"] = final_ensemble_preds

# Show misclassified examples
misclassified_ensemble = df_test_ensemble[df_test_ensemble["label"] != df_test_ensemble["ensemble_predictions"]]

# Display 10 randomly selected misclassified examples
print("Misclassified Examples (Ensemble Model - BERT + SVM + RF + Logistic Regression):")
print(misclassified_ensemble.sample(10))


# Test on Custom Sentences for Ensemble Model (Bert, SVM, Random Forest, and Logistic Regression)

# Define custom sentences
custom_texts = [
    "I am feeling very happy today!",
    "This is the worst day of my life.",
    "I can't stop smiling, this is the best surprise ever!",
    "I am so scared to go outside alone.",
    "I feel so loved and appreciated today.",
    "Why do you always make me so angry?",
    "I feel like crying all day long."
]

# Transform custom sentences using the same TF-IDF vectorizer for ML models
custom_tfidf_features = tfidf_vectorizer.transform(custom_texts)

# Get predictions from ML models
svm_custom_preds = svm_model.predict(custom_tfidf_features)
rf_custom_preds = rf_model.predict(custom_tfidf_features)
log_reg_custom_preds = log_reg_model.predict(custom_tfidf_features)

# Get predictions from the BERT model
custom_tokenized_inputs = tokenizer(custom_texts, return_tensors="pt", padding=True, truncation=True)
custom_tokenized_inputs = {k: v.to(model.device) for k, v in custom_tokenized_inputs.items()}  # Move to device

with torch.no_grad():
    bert_logits = model(**custom_tokenized_inputs).logits
    bert_custom_preds = bert_logits.argmax(dim=1).cpu().numpy()

# Perform Majority Voting for Ensemble Prediction
ensemble_preds = np.array([svm_custom_preds, rf_custom_preds, log_reg_custom_preds, bert_custom_preds])  # Stack predictions
final_ensemble_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=ensemble_preds)

# Emotion Labels Mapping
emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

# Convert predictions to emotion labels
ensemble_custom_preds_labels = [emotion_labels[pred] for pred in final_ensemble_preds]

# Print Predictions
print("Custom Sentence Predictions (Ensemble Model - BERT + SVM + RF + Logistic Regression):\n")
for text, pred_label in zip(custom_texts, ensemble_custom_preds_labels):
    print(f"Sentence: {text}")
    print(f"Ensemble Model Prediction: {pred_label}\n")


# Extract Logits Before Applying argmax() to Ensemble Model (Bert, SVM + Random Forest + Logistic Regression)

def predict_emotion_ensemble(text):
    """
    Function to predict the emotion using the Ensemble Model (BERT + SVM + RF + Logistic Regression).
    Extracts logits (probabilities/decision function values) before applying argmax().
    """
    # Transform input text using the same TF-IDF vectorizer for ML models
    text_tfidf = tfidf_vectorizer.transform([text])

    # Get model outputs (probabilities/logits)
    svm_logits = svm_model.decision_function(text_tfidf)  # Decision function values for SVM
    rf_logits = rf_model.predict_proba(text_tfidf)[0]  # Probabilities for Random Forest
    log_reg_logits = log_reg_model.predict_proba(text_tfidf)[0]  # Probabilities for Logistic Regression

    # Get logits from BERT model
    tokenized_text = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    tokenized_text = {k: v.to(model.device) for k, v in tokenized_text.items()}  # Move to device

    with torch.no_grad():
        bert_logits = model(**tokenized_text).logits.cpu().numpy()[0]  # Extract logits from BERT

    # Normalize SVM logits to match probability scale
    svm_probs = np.exp(svm_logits) / np.sum(np.exp(svm_logits), axis=1, keepdims=True)

    # Average the logits for final ensemble decision
    ensemble_logits = (svm_probs[0] + rf_logits + log_reg_logits + bert_logits) / 4  # Averaging

    # Apply argmax to get the predicted label index
    prediction = np.argmax(ensemble_logits)

    # Emotion labels
    emotion_labels = ["sadness", "joy", "love", "anger", "fear", "surprise"]

    return emotion_labels[prediction], ensemble_logits  # Returning logits along with prediction

# Example Predictions with Logits for Ensemble Model
custom_sentences = [
    "I am feeling very happy today!",  # Expected: Joy
    "I'm so scared of what will happen next.",  # Expected: Fear
    "This is the worst day of my life.",  # Expected: Sadness
    "Wow, this is amazing!"  # Expected: Surprise
]  

# Make predictions and extract logits
print("Ensemble Model Predictions with Logits (BERT + SVM + RF + Logistic Regression):\n")
for text in custom_sentences:
    prediction, logits = predict_emotion_ensemble(text)
    print(f"Sentence: {text}")
    print(f"Ensemble Model Prediction: {prediction}")
    print(f"Logits (Averaged Probabilities): {logits}\n")  # Raw model decision values



